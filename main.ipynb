{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b17df23-2243-45dd-8f6d-5d45c7238cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Get dataset description.\n",
      "2. Generate histograms.\n",
      "3. Check for null values.\n",
      "4. Check for zero values.\n",
      "5. Preprocess the data and train the model.\n",
      "0. Exit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "By using numbers on your keyboard, provide the option you want:  5\n",
      "\n",
      "Provide the train set size:  0.2\n",
      "Provide the random state seeder:  42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######## STARTING PREPROCESSING ########\n",
      "\n",
      "Checking attributes that contain zeros\n",
      "\n",
      "Name of the attribute: length\n",
      "Amount of records with zeros: 0\n",
      "Empty DataFrame\n",
      "Columns: [sex, length, diameter, height, whole_weight, shucked_weight, viscera_weight, shell_weight, rings]\n",
      "Index: []\n",
      "\n",
      "-------\n",
      "\n",
      "Name of the attribute: diameter\n",
      "Amount of records with zeros: 0\n",
      "Empty DataFrame\n",
      "Columns: [sex, length, diameter, height, whole_weight, shucked_weight, viscera_weight, shell_weight, rings]\n",
      "Index: []\n",
      "\n",
      "-------\n",
      "\n",
      "Name of the attribute: height\n",
      "Amount of records with zeros: 2\n",
      "     sex  length  diameter  height  whole_weight  shucked_weight  viscera_weight  shell_weight  rings\n",
      "1257   I   0.430      0.34     0.0         0.428          0.2065          0.0860        0.1150      8\n",
      "3996   I   0.315      0.23     0.0         0.134          0.0575          0.0285        0.3505      6\n",
      "\n",
      "-------\n",
      "\n",
      "Name of the attribute: whole_weight\n",
      "Amount of records with zeros: 0\n",
      "Empty DataFrame\n",
      "Columns: [sex, length, diameter, height, whole_weight, shucked_weight, viscera_weight, shell_weight, rings]\n",
      "Index: []\n",
      "\n",
      "-------\n",
      "\n",
      "Name of the attribute: shucked_weight\n",
      "Amount of records with zeros: 0\n",
      "Empty DataFrame\n",
      "Columns: [sex, length, diameter, height, whole_weight, shucked_weight, viscera_weight, shell_weight, rings]\n",
      "Index: []\n",
      "\n",
      "-------\n",
      "\n",
      "Name of the attribute: viscera_weight\n",
      "Amount of records with zeros: 0\n",
      "Empty DataFrame\n",
      "Columns: [sex, length, diameter, height, whole_weight, shucked_weight, viscera_weight, shell_weight, rings]\n",
      "Index: []\n",
      "\n",
      "-------\n",
      "\n",
      "Name of the attribute: shell_weight\n",
      "Amount of records with zeros: 0\n",
      "Empty DataFrame\n",
      "Columns: [sex, length, diameter, height, whole_weight, shucked_weight, viscera_weight, shell_weight, rings]\n",
      "Index: []\n",
      "\n",
      "-------\n",
      "\n",
      "Name of the attribute: rings\n",
      "Amount of records with zeros: 0\n",
      "Empty DataFrame\n",
      "Columns: [sex, length, diameter, height, whole_weight, shucked_weight, viscera_weight, shell_weight, rings]\n",
      "Index: []\n",
      "\n",
      "-------\n",
      "\n",
      "Data without outliers:\n",
      "                 count      mean       std     min      25%     50%       75%      max\n",
      "length          3783.0  0.520962  0.111547  0.2050  0.45000  0.5350   0.61000   0.7600\n",
      "diameter        3783.0  0.404922  0.092295  0.1550  0.34500  0.4200   0.47500   0.6000\n",
      "height          3783.0  0.137309  0.035302  0.0400  0.11000  0.1400   0.16500   0.2400\n",
      "whole_weight    3783.0  0.791854  0.444751  0.0425  0.43275  0.7665   1.11700   2.1275\n",
      "shucked_weight  3783.0  0.347372  0.203520  0.0170  0.18100  0.3270   0.49200   0.9600\n",
      "viscera_weight  3783.0  0.173810  0.101334  0.0005  0.09050  0.1640   0.24400   0.4920\n",
      "shell_weight    3783.0  0.226082  0.122821  0.0130  0.12500  0.2200   0.31475   0.6250\n",
      "rings           3783.0  9.429289  2.330609  4.0000  8.00000  9.0000  11.00000  15.0000\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "Before transformation:\n",
      "0    M\n",
      "1    M\n",
      "2    F\n",
      "3    M\n",
      "4    I\n",
      "Name: sex, dtype: object\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "After transformation:\n",
      "0    2\n",
      "1    2\n",
      "2    0\n",
      "3    2\n",
      "4    1\n",
      "Name: sex, dtype: int64\n",
      "\n",
      "######## FINISHING PREPROCESSING ########\n",
      "\n",
      "1. Standardization\n",
      "2. Normalization\n",
      "3. Nothing\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 465\u001b[0m\n\u001b[1;32m    463\u001b[0m     check_for_zero_values(return_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m user_input \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m5\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 465\u001b[0m     \u001b[43mhandle_data_preprocessing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m user_input \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBye, see ya!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 406\u001b[0m, in \u001b[0;36mhandle_data_preprocessing\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    403\u001b[0m random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProvide the random state seeder: \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip())\n\u001b[1;32m    405\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m preprocess_data(data, train_size, random_state)\n\u001b[0;32m--> 406\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 411\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(X_train, X_test, y_train, y_test):\n\u001b[1;32m    410\u001b[0m     print_preprocessing_options()\n\u001b[0;32m--> 411\u001b[0m     preprocessing_option \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSelect the preprocessing option: \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m preprocessing_option \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    414\u001b[0m         x_train_scaled, x_test_scaled \u001b[38;5;241m=\u001b[39m standardization(X_train, X_test)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/ipykernel/kernelbase.py:1202\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1200\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/ipykernel/kernelbase.py:1245\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1244\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "pd.set_option('expand_frame_repr', False)\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "names = [\n",
    "    'sex',\n",
    "    'length',\n",
    "    'diameter',\n",
    "    'height',\n",
    "    'whole_weight',\n",
    "    'shucked_weight',\n",
    "    'viscera_weight',\n",
    "    'shell_weight',\n",
    "    'rings',\n",
    "]\n",
    "\n",
    "'''\n",
    "Reading data\n",
    "'''\n",
    "data = pd.read_csv('abalone/abalone.data', names=names)\n",
    "\n",
    "\n",
    "'''\n",
    "Print all available options in the interactive menu\n",
    "'''\n",
    "def print_available_options():\n",
    "    print('\\n1. Get dataset description.')\n",
    "    print('2. Generate histograms.')\n",
    "    print('3. Check for null values.')\n",
    "    print('4. Check for zero values.')\n",
    "    print('5. Preprocess the data and train the model.')\n",
    "    print('0. Exit.')\n",
    "\n",
    "\n",
    "'''\n",
    "Print all available options in terms of preprocessing\n",
    "'''\n",
    "def print_preprocessing_options():\n",
    "    print('\\n1. Standardization')\n",
    "    print('2. Normalization')\n",
    "    print('3. Nothing')\n",
    "\n",
    "\n",
    "'''\n",
    "Print all available models for training\n",
    "'''\n",
    "def print_available_models():\n",
    "    print('\\n1. Linear regression')\n",
    "    print('2. MLP regression')\n",
    "    print('3. Support vector regression')\n",
    "    print('4. Decision tree regression')\n",
    "    print('5. Random forest regression')\n",
    "    print('6. Gradient boosting regression')\n",
    "    print('7. All (+compare results)')\n",
    "\n",
    "\n",
    "'''\n",
    "STANDARDIZATION\n",
    "'''\n",
    "def standardization(x_train, x_test):\n",
    "    std_scaler = StandardScaler()\n",
    "    x_train_scaled = std_scaler.fit_transform(x_train)\n",
    "    x_test_scaled = std_scaler.transform(x_test)\n",
    "    return x_train_scaled, x_test_scaled\n",
    "\n",
    "\n",
    "'''\n",
    "NORMALIZATION\n",
    "'''\n",
    "def normalization(x_train, x_test):\n",
    "    norm_scaler = MinMaxScaler()\n",
    "    norm_scaler.fit(x_train)\n",
    "    x_train_scaled = norm_scaler.transform(x_train)\n",
    "    x_test_scaled = norm_scaler.transform(x_test)\n",
    "    return x_train_scaled, x_test_scaled\n",
    "\n",
    "\n",
    "'''\n",
    "LINEAR REGRESSION\n",
    "'''\n",
    "def linear_regression(x_train, y_train, x_test, y_test):\n",
    "    lr = LinearRegression()\n",
    "\n",
    "    lr.fit(x_train, y_train)\n",
    "    \n",
    "    y_pred = lr.predict(x_test)\n",
    "    \n",
    "    mae_linear_regression = mean_absolute_error(y_test, y_pred)\n",
    "    msa_linear_regression = mean_squared_error(y_test, y_pred)\n",
    "    rmse_linear_regression = np.sqrt(mean_absolute_error(y_test, y_pred))\n",
    "    r2_linear_regression = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f'\\nMAE - Linear Regression: {mae_linear_regression}')\n",
    "    print(f'MSA - Linear Regression: {msa_linear_regression}')\n",
    "    print(f'RMSA - Linear Regression: {rmse_linear_regression}')\n",
    "    print(f'R2 - Linear Regression: {r2_linear_regression}')\n",
    "    \n",
    "    print('---------------------------------------------')\n",
    "\n",
    "\n",
    "'''\n",
    "MLP REGRESSION\n",
    "'''\n",
    "def mlp_regression(x_train, y_train, x_test, y_test):\n",
    "    mlp_regressor = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)\n",
    "    \n",
    "    mlp_regressor.fit(x_train, y_train)\n",
    "    \n",
    "    y_pred = mlp_regressor.predict(x_test)\n",
    "    \n",
    "    mae_mlp = mean_absolute_error(y_test, y_pred)\n",
    "    msa_mlp = mean_squared_error(y_test, y_pred)\n",
    "    rmse_mlp = np.sqrt(mean_absolute_error(y_test, y_pred))\n",
    "    r2_mlp = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f'\\nMAE - MLP Regression: {mae_mlp}')\n",
    "    print(f'MSA - MLP Regression: {msa_mlp}')\n",
    "    print(f'RMSA - MLP Regression: {rmse_mlp}')\n",
    "    print(f'R2 - MLP Regression: {r2_mlp}')\n",
    "    \n",
    "    print('---------------------------------------------')\n",
    "\n",
    "\n",
    "'''\n",
    "SUPPORT VECTOR REGRESSION\n",
    "'''\n",
    "def svr(x_train, y_train, x_test, y_test):\n",
    "    svm = SVR()\n",
    "\n",
    "    svm.fit(x_train, y_train)\n",
    "    \n",
    "    y_pred = svm.predict(x_test)\n",
    "    \n",
    "    mae_svm = mean_absolute_error(y_test, y_pred)\n",
    "    msa_svm = mean_squared_error(y_test, y_pred)\n",
    "    rmse_svm = np.sqrt(mean_absolute_error(y_test, y_pred))\n",
    "    r2_svm = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f'\\nMAE - Support Vector Regression: {mae_svm}')\n",
    "    print(f'MSA - Support Vector Regression: {msa_svm}')\n",
    "    print(f'RMSA - Support Vector Regression: {rmse_svm}')\n",
    "    print(f'R2 - Support Vector Regression: {r2_svm}')\n",
    "    \n",
    "    print('---------------------------------------------')\n",
    "\n",
    "\n",
    "'''\n",
    "DECISION TREE REGRESSION\n",
    "'''\n",
    "def decision_tree_regression(x_train, y_train, x_test, y_test):\n",
    "    dc = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "    dc.fit(x_train, y_train)\n",
    "    \n",
    "    y_pred = dc.predict(x_test)\n",
    "    \n",
    "    mae_dc = mean_absolute_error(y_test, y_pred)\n",
    "    msa_dc = mean_squared_error(y_test, y_pred)\n",
    "    rmse_dc = np.sqrt(mean_absolute_error(y_test, y_pred))\n",
    "    r2_dc = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f'\\nMAE - Decision Tree: {mae_dc}')\n",
    "    print(f'MSA - Decision Tree: {msa_dc}')\n",
    "    print(f'RMSA - Decision Tree: {rmse_dc}')\n",
    "    print(f'R2 - Decision Tree: {r2_dc}')\n",
    "    \n",
    "    print('---------------------------------------------')\n",
    "\n",
    "\n",
    "'''\n",
    "RANDOM FOREST REGRESSION\n",
    "'''\n",
    "def random_forst_regression(x_train, y_train, x_test, y_test):\n",
    "    rf = RandomForestRegressor()\n",
    "\n",
    "    rf.fit(x_train, y_train)\n",
    "    \n",
    "    y_pred = rf.predict(x_test)\n",
    "    \n",
    "    mae_rf = mean_absolute_error(y_test, y_pred)\n",
    "    msa_rf = mean_squared_error(y_test, y_pred)\n",
    "    rmse_rf = np.sqrt(mean_absolute_error(y_test, y_pred))\n",
    "    r2_rf = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f'\\nMAE - Random Forest: {mae_rf}')\n",
    "    print(f'MSA - Random Forest: {msa_rf}')\n",
    "    print(f'RMSA - Random Forest: {rmse_rf}')\n",
    "    print(f'R2 - Random Forest: {r2_rf}')\n",
    "    \n",
    "    print('---------------------------------------------')\n",
    "\n",
    "\n",
    "'''\n",
    "GRADIENT BOOSTING REGRESSION\n",
    "'''\n",
    "def gradient_boosting_regression(x_train, y_train, x_test, y_test):\n",
    "    gbr = GradientBoostingRegressor()\n",
    "\n",
    "    gbr.fit(x_train, y_train)\n",
    "    \n",
    "    y_pred = gbr.predict(x_test)\n",
    "    \n",
    "    mae_gbr = mean_absolute_error(y_test, y_pred)\n",
    "    msa_gbr = mean_squared_error(y_test, y_pred)\n",
    "    rmse_gbr = np.sqrt(mean_absolute_error(y_test, y_pred))\n",
    "    r2_gbr = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f'\\nMAE - Gradient Boosting: {mae_gbr}')\n",
    "    print(f'MSA - Gradient Boosting: {msa_gbr}')\n",
    "    print(f'RMSA - Gradient Boosting: {rmse_gbr}')\n",
    "    print(f'R2 - Gradient Boosting: {r2_gbr}')\n",
    "\n",
    "    print('---------------------------------------------')\n",
    "\n",
    "\n",
    "'''\n",
    "This function is used during preprocessing and allows to\n",
    "find and delete all outliers using interquartile range\n",
    "'''\n",
    "def find_and_delete_outliers(df):\n",
    "    numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "    Q1 = df[numeric_columns].quantile(0.25)\n",
    "    Q3 = df[numeric_columns].quantile(0.75)\n",
    "    \n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers_mask = ((df[numeric_columns] < lower_bound) | (df[numeric_columns] > upper_bound)).any(axis=1)\n",
    "    \n",
    "    return df[~outliers_mask]\n",
    "\n",
    "\n",
    "'''\n",
    "Generates and optionally shows histograms of all attributes\n",
    "(both numerical and categorical)\n",
    "'''\n",
    "def generate_histograms(show=False):\n",
    "    '''\n",
    "    The sex attribute is a categorical attribute, so we need to transform it\n",
    "    '''\n",
    "    data['sex'].value_counts().plot.bar()\n",
    "    data.sex.value_counts().plot.bar()\n",
    "    plt.savefig(f'abalone/pics/hist_sex.png')\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "    '''\n",
    "    Generating charts for all numeric attributes (except the sex attribute)\n",
    "    '''\n",
    "    for name in names[1:]:\n",
    "        data.hist(column=name)\n",
    "        plt.title(f'Histogram of {name}')\n",
    "        plt.xlabel('Values')\n",
    "        plt.ylabel('Frequency')\n",
    "        \n",
    "        plt.savefig(f'abalone/pics/hist_{name}.png')\n",
    "\n",
    "        if show:\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "'''\n",
    "Shows default description of the dataset\n",
    "'''\n",
    "def get_dataset_description():\n",
    "    print('\\nDataset description:')\n",
    "    print(data.describe().T)\n",
    "    print('---------------------------------------------')\n",
    "\n",
    "\n",
    "'''\n",
    "Checks for null values\n",
    "'''\n",
    "def check_for_null_values():\n",
    "    if len(data.isnull()) == len(data):\n",
    "        print('\\nThere are no null values.')\n",
    "    else:\n",
    "        print('\\nThere are null values.')\n",
    "\n",
    "\n",
    "'''\n",
    "Checks for zero values\n",
    "'''\n",
    "def check_for_zero_values(return_values=True):\n",
    "    attributes_with_zeros = []\n",
    "    \n",
    "    for name in names[1:]:\n",
    "        print(f'\\nName of the attribute: {name}')\n",
    "        print(f'Amount of records with zeros: {len(data[data[name] == 0])}')\n",
    "        print(data[data[name] == 0])\n",
    "        print('\\n-------')\n",
    "        \n",
    "        if return_values and len(data[data[name] == 0]) > 0:\n",
    "            attributes_with_zeros.append(name)\n",
    "\n",
    "    if return_values:\n",
    "        return attributes_with_zeros\n",
    "            \n",
    "\n",
    "\n",
    "def preprocess_data(data, train_size=0.2, random_state=42):\n",
    "    '''\n",
    "    All numerical attributes that we are working with cannot equal 0.\n",
    "    Therefore, we need to check where we have these 0 and replace it with means of this attribute.\n",
    "    '''\n",
    "\n",
    "    print('\\n######## STARTING PREPROCESSING ########')\n",
    "\n",
    "    print('\\nChecking attributes that contain zeros')\n",
    "\n",
    "    attributes_with_zeros = check_for_zero_values()\n",
    "\n",
    "    for attribute_with_zeros in attributes_with_zeros:\n",
    "        data_attr_not_zero = data[data[attribute_with_zeros] > 0]\n",
    "    \n",
    "        data_height_not_zero = data[data[attribute_with_zeros] > 0]\n",
    "        means = pd.pivot_table(data_height_not_zero, index=['sex'], aggfunc={attribute_with_zeros: np.mean})\n",
    "\n",
    "        '''\n",
    "        In this case value is hardcoded because we know for what sex\n",
    "        the value is going to be 0 and what we need to select.\n",
    "        '''\n",
    "        mean_to_replace = means.at['I', attribute_with_zeros]\n",
    "        data[attribute_with_zeros] = data[attribute_with_zeros].replace(to_replace=0, value=mean_to_replace)\n",
    "\n",
    "    '''\n",
    "    This line of code is responsible for getting and deleting all outliers.\n",
    "    Check the documentation to this function to get more information.\n",
    "    '''\n",
    "    data = find_and_delete_outliers(data)\n",
    "    \n",
    "    print('\\nData without outliers:')\n",
    "    print(data.describe().T)\n",
    "\n",
    "    print('\\n---------------------------------------------')\n",
    "    print('\\nBefore transformation:')\n",
    "    print(data.head()['sex'])\n",
    "\n",
    "    '''\n",
    "    Transformation of categorical data to numerical data\n",
    "    '''\n",
    "    sex_attribute_only = data['sex']\n",
    "    lbe = LabelEncoder()\n",
    "    data['sex'] = lbe.fit_transform(sex_attribute_only)\n",
    "\n",
    "    print('\\n---------------------------------------------')\n",
    "    print('\\nAfter transformation:')\n",
    "    print(data.head()['sex'])\n",
    "\n",
    "    print('\\n######## FINISHING PREPROCESSING ########')\n",
    "\n",
    "    '''\n",
    "    Label (what we are trying to predict) and estimators (the rest of attributes)\n",
    "    '''\n",
    "    label = data['rings']\n",
    "    estimators = data.drop('rings', axis=1)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(estimators, label, train_size=train_size, random_state=random_state)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "'''\n",
    "Interactive menu helper functions\n",
    "'''\n",
    "\n",
    "\n",
    "def handle_histograms():\n",
    "    show_histograms = input('\\nDo you want to show histograms on the screen before saving? [y/n]: ').strip()\n",
    "    \n",
    "    if show_histograms == 'y':\n",
    "        generate_histograms(show=True)\n",
    "    elif show_histograms == 'n':\n",
    "        generate_histograms(show=False)\n",
    "    else:\n",
    "        print('Wrong answer, try again.')\n",
    "\n",
    "\n",
    "def handle_data_preprocessing(data):\n",
    "    train_size = float(input('\\nProvide the train set size: ').strip())\n",
    "    random_state = int(input('Provide the random state seeder: ').strip())\n",
    "\n",
    "    X_train, X_test, y_train, y_test = preprocess_data(data, train_size, random_state)\n",
    "    train_model(X_train, X_test, y_train, y_test)\n",
    "\n",
    "\n",
    "def train_model(X_train, X_test, y_train, y_test):\n",
    "    print_preprocessing_options()\n",
    "    preprocessing_option = input('Select the preprocessing option: ').strip()\n",
    "\n",
    "    if preprocessing_option == '1':\n",
    "        x_train_scaled, x_test_scaled = standardization(X_train, X_test)\n",
    "        X_train = x_train_scaled\n",
    "        X_test = x_test_scaled\n",
    "    elif preprocessing_option == '2':\n",
    "        x_train_scaled, x_test_scaled = normalization(X_train, X_test)\n",
    "        X_train = x_train_scaled\n",
    "        X_test = x_test_scaled\n",
    "    elif preprocessing_option == '3':\n",
    "        pass\n",
    "    else:\n",
    "        print('You have select the wrong preprocessing option, please try again.')\n",
    "        return\n",
    "\n",
    "    print_available_models()\n",
    "    model_option = input('Select the model you want to use: ').strip()\n",
    "\n",
    "    if model_option == '1':\n",
    "        linear_regression(X_train, y_train, X_test, y_test)\n",
    "    elif model_option == '2':\n",
    "        mlp_regression(X_train, y_train, X_test, y_test)\n",
    "    elif model_option == '3':\n",
    "        svr(X_train, y_train, X_test, y_test)\n",
    "    elif model_option == '4':\n",
    "        decision_tree_regression(X_train, y_train, X_test, y_test)\n",
    "    elif model_option == '5':\n",
    "        random_forst_regression(X_train, y_train, X_test, y_test)\n",
    "    elif model_option == '6':\n",
    "        gradient_boosting_regression(X_train, y_train, X_test, y_test)\n",
    "    elif model_option == '7':\n",
    "        # TODO Implement the full training + compare the results\n",
    "        pass\n",
    "    else:\n",
    "        print('You have selected the wrong model option, please try again.')\n",
    "        return\n",
    "\n",
    "\n",
    "'''\n",
    "Interactive menu\n",
    "'''\n",
    "while True:\n",
    "    print_available_options()\n",
    "    user_input = input('By using numbers on your keyboard, provide the option you want: ').strip()\n",
    "\n",
    "    if user_input == '1':\n",
    "        get_dataset_description()\n",
    "    elif user_input == '2':\n",
    "        handle_histograms()\n",
    "    elif user_input == '3':\n",
    "        check_for_null_values()\n",
    "    elif user_input == '4':\n",
    "        check_for_zero_values(return_values=False)\n",
    "    elif user_input == '5':\n",
    "        handle_data_preprocessing(data)\n",
    "    elif user_input == '0':\n",
    "        print('\\nBye, see ya!')\n",
    "        break\n",
    "    else:\n",
    "        print('\\nLooks like it is the wrong option, try again :(')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
